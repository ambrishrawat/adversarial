{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "import skimage\n",
    "from skimage import io\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(img_filename):\n",
    "    \"\"\"\n",
    "    Load image from the filename. Default is to load in color if\n",
    "    possible.\n",
    "    Args:\n",
    "        img_name (string): string of the image name, relative to\n",
    "            the image directory.\n",
    "    Returns:\n",
    "        np array of float32: an image as a numpy array of float32\n",
    "    \"\"\"\n",
    "    img = skimage.img_as_float(imread(\n",
    "        img_filename,mode='RGB')).astype(np.float32)\n",
    "    if img.ndim == 2:\n",
    "        img = img[:, :, np.newaxis]\n",
    "    elif img.shape[2] == 4:\n",
    "        img = img[:, :, :3]\n",
    "    \n",
    "    '''Subtract channel vise mean'''\n",
    "    ch_mean = np.load('preprocessing/ch_mean.npy')\n",
    "    img = img - ch_mean\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DictIterator():\n",
    "    '''\n",
    "    Class for iterating over a pandas data frame with filenames and addresses\n",
    "\n",
    "    TODO\n",
    "    add comments\n",
    "    '''\n",
    "    def __init__(self,csv_location = None,\n",
    "                 batch_size=32,\n",
    "                 shuffle=False,\n",
    "                 target_size=(64,64)):\n",
    "        \n",
    "        if csv_location is not None:\n",
    "            self.df = pd.read_csv(csv_location)\n",
    "        self.N = self.df.shape[0]\n",
    "        print(self.N)\n",
    "        self.batch_size = batch_size\n",
    "        self.total_batches_seen = 0\n",
    "        self.index_gen = self._idx_gen(self.N,batch_size,shuffle)\n",
    "        self.target_size = target_size\n",
    "        self.img_set = None\n",
    "        \n",
    "    def _idx_gen(self,N,batch_size=32,shuffle=False):\n",
    "        batch_index = 0\n",
    "        while 1:\n",
    "            if batch_index == 0:\n",
    "                index_array = np.arange(N)\n",
    "                if shuffle:\n",
    "                    index_array = np.random.permutation(N)\n",
    "            current_index = (batch_index * batch_size) % N\n",
    "            if N >= current_index + batch_size:\n",
    "                current_batch_size = batch_size\n",
    "                batch_index += 1\n",
    "            else:\n",
    "                current_batch_size = N - current_index\n",
    "                batch_index = 0\n",
    "            self.total_batches_seen += 1\n",
    "            yield (index_array[current_index: current_index + current_batch_size],\n",
    "                   current_index, current_batch_size)\n",
    "            \n",
    "    def batch_gen(self):\n",
    "        while 1:\n",
    "            index_array, current_index, current_batch_size = self.index_gen.__next__()\n",
    "            img = [imresize(load_img(self.df.iloc[i]['filename']),size=self.target_size) for i in index_array]\n",
    "            img = np.array(img)\n",
    "            lab = [self.df.iloc[i].iloc[1:].values.astype('float32') for i in index_array]\n",
    "            lab = np.array(lab)\n",
    "            print(img.shape)\n",
    "            print(lab.shape)\n",
    "            plt.imshow(img[0])\n",
    "            yield img,lab\n",
    "    \n",
    "    def channel_mean(self):\n",
    "        self.img_set = np.array([load_img(self.df.iloc[i]['filename']) for i in range(self.N)])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "d = DictIterator(csv_location='preprocessing/trainset.csv')\n",
    "d.channel_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(d.img_set.shape)\n",
    "r = np.mean(d.img_set[:,:,:,0],  axis=0)\n",
    "g = np.mean(d.img_set[:,:,:,1],  axis=0)\n",
    "b = np.mean(d.img_set[:,:,:,2],  axis=0)\n",
    "\n",
    "\n",
    "\n",
    "np.save('preprocessing/r.npy',r)\n",
    "np.save('preprocessing/g.npy',g)\n",
    "np.save('preprocessing/b.npy',b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "ch_mean = np.zeros((64,64,3))\n",
    "print(ch_mean.shape)\n",
    "ch_mean[:,:,0] = r\n",
    "ch_mean[:,:,1] = g\n",
    "ch_mean[:,:,2] = b\n",
    "np.save('preprocessing/ch_mean.npy',ch_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model_defs import *\n",
    "from utils import *\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_modelx(csv_location='preprocessing/valset.csv',batch_size=64,mid='m1'):\n",
    "\n",
    "\n",
    "    #define the batch generator   (validation set)\n",
    "    val_datagen = CSVGenerator(csv_location=csv_location,\n",
    "                                 batch_size=batch_size)\n",
    "\n",
    "    val_generator = val_datagen.batch_gen()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 64, 64, 3))\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open('models/'+mid+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(\"models/\"+mid+\".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    d = val_generator.__next__()\n",
    "    pred = model(x)\n",
    "    pred\n",
    "    # evaluate loaded model on test data\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    #val_loss = model.evaluate_generator(\n",
    "    #   generator = val_generator,\n",
    "    #   val_samples = val_datagen.get_data_size())\n",
    "\n",
    "    #print(\"%s: %.2f%%\" % (model.metrics_names[1], val_loss[1]*100))\n",
    "    #print(val_loss)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "try_modelx()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directory = '/dccstor/dlw/ambrish/examples/adversarial/models/m1'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mid = 'm1'\n",
    "epoch = 100\n",
    "val_loss = [1.32,23.4]\n",
    "with open('models/'+mid+'/acc_log.csv','a') as resultFile:\n",
    "    r = np.concatenate([np.asarray([epoch]),val_loss])\n",
    "    wr = csv.writer(resultFile,lineterminator='\\n')\n",
    "    \n",
    "    wr.writerows([r])\n",
    "    wr.writerow(['f','r','r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "import skimage\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "class tinyImageNet(object):\n",
    "\n",
    "    def __init__(self,fpath=None):\n",
    "        self.fpath = fpath\n",
    "        self.classes = None\n",
    "\n",
    "    def make_train_csv(self):\n",
    "        '''\n",
    "        for tiny ImageNet folder structure (train)\n",
    "        '''\n",
    "        self.classes = listdir(os.path.join(self.fpath,'train'))\n",
    "        num_classes = len(self.classes)\n",
    "        traincsv_file = Path('trainset.csv')\n",
    "        if traincsv_file.is_file():\n",
    "            pass\n",
    "        else:\n",
    "            with open('trainset.csv', 'wt') as csvfile:\n",
    "                csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "                csvwriter.writerow(['filename']+self.classes) #csv header\n",
    "    \n",
    "                c_idx = 0\n",
    "                for class_ in self.classes:\n",
    "                    class_path = os.path.join(self.fpath,'train',class_,'images')\n",
    "                    images_ = listdir(class_path)\n",
    "                    for image_ in images_:\n",
    "    \n",
    "                        file_path = os.path.join(class_path,image_)\n",
    "    \n",
    "                        label = np.zeros(num_classes)\n",
    "                        label[c_idx] = 1\n",
    "    \n",
    "                        csvwriter.writerow([file_path] + list(map(str, label)))\n",
    "                    c_idx+=1\n",
    "\n",
    "    def make_val_csv(self):\n",
    "        '''\n",
    "        for tiny ImageNet folder structure (val)\n",
    "        '''\n",
    "        valcsv_file = Path('val.csv')\n",
    "        if valcsv_file.is_file():\n",
    "            pass\n",
    "        else:\n",
    "            with open(os.path.join(self.fpath,'val/val_annotations.txt'), 'rt') as csvfile:\n",
    "                \n",
    "                reader = csv.reader(csvfile, delimiter='\\t')\n",
    "                \n",
    "                with open('valset.csv', 'wt') as csvfile:\n",
    "                    \n",
    "                    csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "                    csvwriter.writerow(['filename']+self.classes)\n",
    "                    \n",
    "                    for row in reader:\n",
    "\n",
    "                        file_path = os.path.join(self.fpath,'val','images',row[0])\n",
    "                        \n",
    "                        label = np.zeros(len(self.classes))\n",
    "                        label[self.classes.index(row[1])] = 1\n",
    "                        \n",
    "                        csvwriter.writerow([file_path] + list(map(str, label)))            \n",
    "                \n",
    "    def make_csvs(self):\n",
    "        self.make_train_csv()\n",
    "        self.make_val_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
